{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getTargetScores_SentenceBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCWM0poWJSgb"
      },
      "source": [
        "This file uses the fine-tuned model to get embeddings by calculating the most similar train text to the input (i.e., test) text, and assigning it the score of that similar text.\n",
        "\n",
        "A large portion of this code is written by Mathis Lucka ([GitHub](https://github.com/mathislucka), [Kaggle](https://www.kaggle.com/mathislucka))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xXhqSqeJRIN"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKxcJTyfN_uu"
      },
      "source": [
        "!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU1SyKnRJMvD"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import semantic_search\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaILMjntMDK8"
      },
      "source": [
        "# Open up gdrive to get files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHy8cl94MG4f"
      },
      "source": [
        "# Globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMROgZOXMIDv"
      },
      "source": [
        "FOLD = 3\n",
        "BASE_PATH = 'gdrive/My Drive/colabNotebooks/commonLitReadabilityPrize/quantProject'\n",
        "ONLY_COMMONLIT_TRAIN_DATA_PATH = os.path.join(BASE_PATH, 'data/training/original/train.csv')\n",
        "ORIGINAL_DATASET_PATH = os.path.join(BASE_PATH, 'data/training/allData/fullset.csv')\n",
        "ENCODINGS_ORIGINAL_DATASET_PATH = os.path.join(BASE_PATH, 'finalEncodings/sentenceBERT.csv')\n",
        "FULL_CLEAR_CORPUS_PATH = os.path.join(BASE_PATH, 'data/clearCorpus/clearCorpus.csv') # has test & train sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV_hHiGNkKKH"
      },
      "source": [
        "# Make the full corpus into a dataframe\n",
        "FULL_CLEAR_CORPUS_DF = pd.read_csv(FULL_CLEAR_CORPUS_PATH)\n",
        "\n",
        "# Get test set from full corpus\n",
        "isTest_Bool = FULL_CLEAR_CORPUS_DF['testOrTrain'] == 'Test'\n",
        "TEST_SET_TEXT = FULL_CLEAR_CORPUS_DF[isTest_Bool]['Excerpt']\n",
        "TEST_SET_TARGET = FULL_CLEAR_CORPUS_DF[isTest_Bool]['BT_easiness']\n",
        "\n",
        "# Get train set from full corpus\n",
        "isTrain_Bool = FULL_CLEAR_CORPUS_DF['testOrTrain'] == 'Train'\n",
        "TRAIN_SET_TEXT = FULL_CLEAR_CORPUS_DF[isTrain_Bool]['Excerpt']\n",
        "TRAIN_SET_TARGET = FULL_CLEAR_CORPUS_DF[isTrain_Bool]['BT_easiness']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WULr6GlpjEZ2"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8dZCMMSegRO"
      },
      "source": [
        "#### USING A FINE-TUNED MODEL ####\n",
        "\n",
        "testExcerpts = TEST_SET_TEXT.tolist()\n",
        "testTargets = TEST_SET_TARGET.tolist()\n",
        "print('Num test: ', len(testExcerpts))\n",
        "# full data set w/ external data\n",
        "trainExcerpts = (pd.read_csv(ORIGINAL_DATASET_PATH)).excerpt.tolist()\n",
        "print('Num train: ', len(trainExcerpts))\n",
        "trainTargets = (pd.read_csv(ORIGINAL_DATASET_PATH)).target.tolist()\n",
        "\n",
        "sbertModel = SentenceTransformer('gdrive/MyDrive/colabNotebooks/commonLitReadabilityPrize/firstPlace_CodeFiles/models/finalModel_robertabase_simplerAlgo/model_fold_{}_simplerAlgo'.format(FOLD))\n",
        "\n",
        "queriesTestSet = sbertModel.encode(testExcerpts)\n",
        "#print(queriesTestSet)\n",
        "# Get sentence embeddings for the model we trained\n",
        "fullSetEmbeddings = sbertModel.encode(trainExcerpts)\n",
        "#print(fullSetEmbeddings)\n",
        "\n",
        "similarMatches = semantic_search(queriesTestSet, fullSetEmbeddings, top_k=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdF5L95oiI7e"
      },
      "source": [
        "# Printing the top hit for each of the samples above from \n",
        "#   this portion is using the model I trained \n",
        "#   can compare the hits with the ones from the samples printed above\n",
        "listOfTargets = []\n",
        "for match in similarMatches:\n",
        "  print(trainExcerpts[match[0]['corpus_id']])\n",
        "  print(trainTargets[match[0]['corpus_id']])\n",
        "  listOfTargets.append(trainTargets[match[0]['corpus_id']])\n",
        "  print('--')\n",
        "\n",
        "print(len(listOfTargets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5hph6B_iqTN"
      },
      "source": [
        "# RMSE\n",
        "rms2 = mean_squared_error(testTargets, listOfTargets, squared=False)\n",
        "print('RMSE: ', rms2)\n",
        "\n",
        "print('R-squared Score: ', r2_score(testTargets, listOfTargets))\n",
        "\n",
        "# RMSE best distilroberta: model fold 4 = 0.7935653654411279\n",
        "# RMSE best roberta-base: model fold 0 = 0.7560099182727237 (didn't check the other folds)\n",
        "# RMSE best finalModel (trained on distilroberta): model fold 5 = 0.5902524799847981\n",
        "# RMSE best finalModel (trained on roberta-base): model fold 3 = 0.559884461712637\n",
        "# RMSE best finalModel (trained on deberta-base): model fold 1 = 0.5617638620548048\n",
        "\n",
        "# With fine-tuned roberta-base:\n",
        "#RMSE:  0.559884461712637\n",
        "#R-squared Score:  0.7066733375116456"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}